{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from lxml import html\n",
    "from lxml.html import fromstring\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "import re\n",
    "#import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Trending  developers on GitHub today · GitHub</title>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tim Paine']\n",
      "['Kyle Mathews']\n",
      "['XhmikosR']\n",
      "['Forbes Lindesay']\n",
      "['oznu']\n",
      "['Jethro Kuan']\n",
      "['Hang Zhang']\n",
      "['Chris Banes']\n",
      "['Whyrusleeping']\n",
      "['Florian Märkl']\n",
      "['Hiroshi Kimura']\n",
      "['Bartlomiej Plotka']\n",
      "['William Candillon']\n",
      "['Sascha Grunert']\n",
      "['Michiel Borkent']\n",
      "['Said Tahsin Dane']\n",
      "['Richard Schneeman']\n",
      "['Ingo Bürk']\n",
      "['Maartje Eyskens']\n",
      "['Stanislas']\n",
      "['Harsh Shandilya']\n",
      "['Jason Miller']\n",
      "['Yu Che']\n",
      "['Marten Seemann']\n",
      "['Cristiano Calcagno']\n"
     ]
    }
   ],
   "source": [
    "#soup.body.article.h1.a.text\n",
    "\n",
    "table = soup.find_all('div',{'class':'explore-pjax-container container-lg p-responsive pt-6'})[0]\n",
    "article = table.find_all('article',{'class':'Box-row d-flex'})\n",
    "h1=  table.find_all('h1',{'class':'h3 lh-condensed'})\n",
    "for a in h1:\n",
    "    print (a.text.replace('\\n\\n','\\n').strip().split(\"\\n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Trending Python repositories on GitHub today · GitHub</title>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['podgorskiy /      ALAE']\n",
      "['timgrossmann /      InstaPy']\n",
      "['3b1b /      manim']\n",
      "['TheAlgorithms /      Python']\n",
      "['donnemartin /      system-design-primer']\n",
      "['TachibanaYoshino /      AnimeGAN']\n",
      "['alexgand /      springer_free_books']\n",
      "['soimort /      you-get']\n",
      "['scikit-learn /      scikit-learn']\n",
      "['freqtrade /      freqtrade']\n",
      "['NVlabs /      stylegan2']\n",
      "['programthink /      zhao']\n",
      "['volatilityfoundation /      volatility']\n",
      "['Manisso /      fsociety']\n",
      "['PyTorchLightning /      pytorch-lightning']\n",
      "['OctoPrint /      OctoPrint']\n",
      "['iperov /      DeepFaceLab']\n",
      "['matplotlib /      mplfinance']\n",
      "['NVIDIA /      apex']\n",
      "['Alic-yuan /      nlp-beginner-finish']\n",
      "['commaai /      comma10k']\n",
      "['ycm-core /      YouCompleteMe']\n",
      "['apprenticeharper /      DeDRM_tools']\n",
      "['google-research /      bert']\n",
      "['neha-chawla /      RandomPython']\n"
     ]
    }
   ],
   "source": [
    "table = soup.find_all('div',{'class':'explore-pjax-container container-lg p-responsive pt-6'})[0]\n",
    "article = table.find_all('article',{'class':'Box-row'})[0]\n",
    "h1=  table.find_all('h1',{'class':'h3 lh-condensed'})\n",
    "h1\n",
    "for a in h1:\n",
    "    print (a.text.replace('\\n','').strip().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Walt Disney - Wikipedia</title>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"image\" href=\"/wiki/File:Walt_Disney_1946.JPG\"><img alt=\"Walt Disney 1946.JPG\" data-file-height=\"675\" data-file-width=\"450\" decoding=\"async\" height=\"330\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/330px-Walt_Disney_1946.JPG 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/440px-Walt_Disney_1946.JPG 2x\" width=\"220\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Walt_Disney_1942_signature.svg\"><img alt=\"Walt Disney 1942 signature.svg\" data-file-height=\"218\" data-file-width=\"585\" decoding=\"async\" height=\"56\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/225px-Walt_Disney_1942_signature.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/300px-Walt_Disney_1942_signature.svg.png 2x\" width=\"150\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Walt_Disney_envelope_ca._1921.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"1086\" data-file-width=\"1576\" decoding=\"async\" height=\"152\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/330px-Walt_Disney_envelope_ca._1921.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/440px-Walt_Disney_envelope_ca._1921.jpg 2x\" width=\"220\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Trolley_Troubles_poster.jpg\"><img alt=\"A cartoon rabbit is driving a tramcar; other cartoon rabbits are in, under, on and around the car.\" class=\"thumbimage\" data-file-height=\"1600\" data-file-width=\"1202\" decoding=\"async\" height=\"226\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/255px-Trolley_Troubles_poster.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/340px-Trolley_Troubles_poster.jpg 2x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg\"><img alt=\"Walt Disney with Mickey Mouse\" class=\"thumbimage\" data-file-height=\"1028\" data-file-width=\"915\" decoding=\"async\" height=\"191\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/170px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/255px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/340px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg 2x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Steamboat-willie.jpg\"><img alt=\"A cartoon mouse is operating a ship's steering wheel\" class=\"thumbimage\" data-file-height=\"267\" data-file-width=\"373\" decoding=\"async\" height=\"122\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/255px-Steamboat-willie.jpg 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/340px-Steamboat-willie.jpg 2x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Walt_Disney_1935.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"451\" data-file-width=\"358\" decoding=\"async\" height=\"214\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/255px-Walt_Disney_1935.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/340px-Walt_Disney_1935.jpg 2x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Walt_Disney_Snow_white_1937_trailer_screenshot_(13).jpg\"><img alt=\"Walt Disney sits in front of a set of models of the seven dwarfs\" class=\"thumbimage\" data-file-height=\"388\" data-file-width=\"500\" decoding=\"async\" height=\"171\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/330px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/440px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg 2x\" width=\"220\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Disney_drawing_goofy.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"770\" data-file-width=\"600\" decoding=\"async\" height=\"218\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/255px-Disney_drawing_goofy.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/340px-Disney_drawing_goofy.jpg 2x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:DisneySchiphol1951.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"2493\" data-file-width=\"3247\" decoding=\"async\" height=\"169\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/330px-DisneySchiphol1951.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/440px-DisneySchiphol1951.jpg 2x\" width=\"220\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:WaltDisneyplansDisneylandDec1954.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"2417\" data-file-width=\"2723\" decoding=\"async\" height=\"195\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/330px-WaltDisneyplansDisneylandDec1954.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/440px-WaltDisneyplansDisneylandDec1954.jpg 2x\" width=\"220\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Walt_disney_portrait_right.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"902\" data-file-width=\"667\" decoding=\"async\" height=\"230\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/255px-Walt_disney_portrait_right.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/340px-Walt_disney_portrait_right.jpg 2x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Walt_Disney_Grave.JPG\"><img alt=\"A gravestone inscribed 'Walter Elias Disney', 'Lillian Bounds Disney', 'Robert B. Brown', Sharon Disney Brown Lund ashes scattered in paradise'\" class=\"thumbimage\" data-file-height=\"1700\" data-file-width=\"1400\" decoding=\"async\" height=\"206\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/255px-Walt_Disney_Grave.JPG 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/340px-Walt_Disney_Grave.JPG 2x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Roy_O._Disney_with_Company_at_Press_Conference.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"275\" data-file-width=\"220\" decoding=\"async\" height=\"213\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg 1.5x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Disney_Display_Case.JPG\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"3025\" data-file-width=\"1927\" decoding=\"async\" height=\"267\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Disney_Display_Case.JPG/170px-Disney_Display_Case.JPG\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Disney_Display_Case.JPG/255px-Disney_Display_Case.JPG 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Disney_Display_Case.JPG/340px-Disney_Display_Case.JPG 2x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Disney1968.jpg\"><img alt=\"A portrait of Disney with cartoon representations of different nationalities on a 6 cent US stamp\" class=\"thumbimage\" data-file-height=\"736\" data-file-width=\"483\" decoding=\"async\" height=\"259\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/255px-Disney1968.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/340px-Disney1968.jpg 2x\" width=\"170\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:The_Walt_Disney_Company_Logo.svg\"><img alt=\"The Walt Disney Company Logo.svg\" data-file-height=\"135\" data-file-width=\"890\" decoding=\"async\" height=\"18\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/44/The_Walt_Disney_Company_Logo.svg/120px-The_Walt_Disney_Company_Logo.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/44/The_Walt_Disney_Company_Logo.svg/180px-The_Walt_Disney_Company_Logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/44/The_Walt_Disney_Company_Logo.svg/240px-The_Walt_Disney_Company_Logo.svg.png 2x\" width=\"120\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Animation_disc.svg\"><img alt=\"Animation disc.svg\" data-file-height=\"28\" data-file-width=\"30\" decoding=\"async\" height=\"28\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/30px-Animation_disc.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/45px-Animation_disc.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/60px-Animation_disc.svg.png 2x\" width=\"30\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:P_vip.svg\"><img alt=\"P vip.svg\" data-file-height=\"1944\" data-file-width=\"1911\" decoding=\"async\" height=\"30\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/29px-P_vip.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/44px-P_vip.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/59px-P_vip.svg.png 2x\" width=\"29\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Magic_Kingdom_castle.jpg\"><img alt=\"Magic Kingdom castle.jpg\" data-file-height=\"1545\" data-file-width=\"1262\" decoding=\"async\" height=\"30\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/24px-Magic_Kingdom_castle.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/37px-Magic_Kingdom_castle.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/49px-Magic_Kingdom_castle.jpg 2x\" width=\"24\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Video-x-generic.svg\"><img alt=\"Video-x-generic.svg\" data-file-height=\"48\" data-file-width=\"48\" decoding=\"async\" height=\"30\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/30px-Video-x-generic.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/45px-Video-x-generic.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/60px-Video-x-generic.svg.png 2x\" width=\"30\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Flag_of_Los_Angeles_County,_California.svg\"><img alt=\"Flag of Los Angeles County, California.svg\" data-file-height=\"913\" data-file-width=\"1522\" decoding=\"async\" height=\"18\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/30px-Flag_of_Los_Angeles_County%2C_California.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/45px-Flag_of_Los_Angeles_County%2C_California.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/60px-Flag_of_Los_Angeles_County%2C_California.svg.png 2x\" width=\"30\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Blank_television_set.svg\"><img alt=\"Blank television set.svg\" data-file-height=\"92\" data-file-width=\"138\" decoding=\"async\" height=\"20\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/30px-Blank_television_set.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/45px-Blank_television_set.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/60px-Blank_television_set.svg.png 2x\" width=\"30\"/></a>\n",
      "<a class=\"image\" href=\"/wiki/File:Flag_of_the_United_States.svg\"><img alt=\"Flag of the United States.svg\" data-file-height=\"650\" data-file-width=\"1235\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/30px-Flag_of_the_United_States.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/45px-Flag_of_the_United_States.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/60px-Flag_of_the_United_States.svg.png 2x\" width=\"30\"/></a>\n"
     ]
    }
   ],
   "source": [
    "todo=soup.find_all('div',{'class':'mw-body'})[0]\n",
    "images = todo.find_all('a',{'class':'image'})\n",
    "for ima in images:\n",
    "    print (ima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Python - Wikipedia</title>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' \n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the URL: #mw-head\n",
      "Found the URL: #p-search\n",
      "Found the URL: https://en.wiktionary.org/wiki/Python\n",
      "Found the URL: https://en.wiktionary.org/wiki/python\n",
      "Found the URL: #Snakes\n",
      "Found the URL: #Ancient_Greece\n",
      "Found the URL: #Media_and_entertainment\n",
      "Found the URL: #Computing\n",
      "Found the URL: #Engineering\n",
      "Found the URL: #Roller_coasters\n",
      "Found the URL: #Vehicles\n",
      "Found the URL: #Weaponry\n",
      "Found the URL: #People\n",
      "Found the URL: #Other_uses\n",
      "Found the URL: #See_also\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=1\n",
      "Found the URL: /wiki/Pythonidae\n",
      "Found the URL: /wiki/Python_(genus)\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=2\n",
      "Found the URL: /wiki/Python_(mythology)\n",
      "Found the URL: /wiki/Python_of_Aenus\n",
      "Found the URL: /wiki/Python_(painter)\n",
      "Found the URL: /wiki/Python_of_Byzantium\n",
      "Found the URL: /wiki/Python_of_Catana\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=3\n",
      "Found the URL: /wiki/Python_(film)\n",
      "Found the URL: /wiki/Pythons_2\n",
      "Found the URL: /wiki/Monty_Python\n",
      "Found the URL: /wiki/Python_(Monty)_Pictures\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=4\n",
      "Found the URL: /wiki/Python_(programming_language)\n",
      "Found the URL: /wiki/CPython\n",
      "Found the URL: /wiki/CMU_Common_Lisp\n",
      "Found the URL: /wiki/PERQ#PERQ_3\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=5\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=6\n",
      "Found the URL: /wiki/Python_(Busch_Gardens_Tampa_Bay)\n",
      "Found the URL: /wiki/Python_(Coney_Island,_Cincinnati,_Ohio)\n",
      "Found the URL: /wiki/Python_(Efteling)\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=7\n",
      "Found the URL: /wiki/Python_(automobile_maker)\n",
      "Found the URL: /wiki/Python_(Ford_prototype)\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=8\n",
      "Found the URL: /wiki/Colt_Python\n",
      "Found the URL: /wiki/Python_(missile)\n",
      "Found the URL: /wiki/Python_(nuclear_primary)\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=9\n",
      "Found the URL: /wiki/Python_Anghelo\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=10\n",
      "Found the URL: /wiki/PYTHON\n",
      "Found the URL: /w/index.php?title=Python&action=edit&section=11\n",
      "Found the URL: /wiki/Cython\n",
      "Found the URL: /wiki/Pyton\n",
      "Found the URL: /wiki/File:Disambig_gray.svg\n",
      "Found the URL: /wiki/Help:Disambiguation\n",
      "Found the URL: https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0\n",
      "Found the URL: https://en.wikipedia.org/w/index.php?title=Python&oldid=943216744\n",
      "Found the URL: /wiki/Help:Category\n",
      "Found the URL: /wiki/Category:Disambiguation_pages\n",
      "Found the URL: /wiki/Category:Disambiguation_pages_with_short_description\n",
      "Found the URL: /wiki/Category:All_article_disambiguation_pages\n",
      "Found the URL: /wiki/Category:All_disambiguation_pages\n",
      "Found the URL: /wiki/Category:Animal_common_name_disambiguation_pages\n",
      "Found the URL: /wiki/Special:MyTalk\n",
      "Found the URL: /wiki/Special:MyContributions\n",
      "Found the URL: /w/index.php?title=Special:CreateAccount&returnto=Python\n",
      "Found the URL: /w/index.php?title=Special:UserLogin&returnto=Python\n",
      "Found the URL: /wiki/Python\n",
      "Found the URL: /wiki/Talk:Python\n",
      "Found the URL: /wiki/Python\n",
      "Found the URL: /w/index.php?title=Python&action=edit\n",
      "Found the URL: /w/index.php?title=Python&action=history\n",
      "Found the URL: /wiki/Main_Page\n",
      "Found the URL: /wiki/Main_Page\n",
      "Found the URL: /wiki/Wikipedia:Contents\n",
      "Found the URL: /wiki/Wikipedia:Featured_content\n",
      "Found the URL: /wiki/Portal:Current_events\n",
      "Found the URL: /wiki/Special:Random\n",
      "Found the URL: https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
      "Found the URL: //shop.wikimedia.org\n",
      "Found the URL: /wiki/Help:Contents\n",
      "Found the URL: /wiki/Wikipedia:About\n",
      "Found the URL: /wiki/Wikipedia:Community_portal\n",
      "Found the URL: /wiki/Special:RecentChanges\n",
      "Found the URL: //en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "Found the URL: /wiki/Special:WhatLinksHere/Python\n",
      "Found the URL: /wiki/Special:RecentChangesLinked/Python\n",
      "Found the URL: /wiki/Wikipedia:File_Upload_Wizard\n",
      "Found the URL: /wiki/Special:SpecialPages\n",
      "Found the URL: /w/index.php?title=Python&oldid=943216744\n",
      "Found the URL: /w/index.php?title=Python&action=info\n",
      "Found the URL: https://www.wikidata.org/wiki/Special:EntityPage/Q747452\n",
      "Found the URL: /w/index.php?title=Special:CiteThisPage&page=Python&id=943216744&wpFormIdentifier=titleform\n",
      "Found the URL: https://commons.wikimedia.org/wiki/Category:Python\n",
      "Found the URL: /w/index.php?title=Special:Book&bookcmd=book_creator&referer=Python\n",
      "Found the URL: /w/index.php?title=Special:ElectronPdf&page=Python&action=show-download-screen\n",
      "Found the URL: /w/index.php?title=Python&printable=yes\n",
      "Found the URL: https://af.wikipedia.org/wiki/Python\n",
      "Found the URL: https://als.wikipedia.org/wiki/Python\n",
      "Found the URL: https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86\n",
      "Found the URL: https://az.wikipedia.org/wiki/Python\n",
      "Found the URL: https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)\n",
      "Found the URL: https://be.wikipedia.org/wiki/Python\n",
      "Found the URL: https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)\n",
      "Found the URL: https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)\n",
      "Found the URL: https://da.wikipedia.org/wiki/Python\n",
      "Found the URL: https://de.wikipedia.org/wiki/Python\n",
      "Found the URL: https://eo.wikipedia.org/wiki/Pitono_(apartigilo)\n",
      "Found the URL: https://eu.wikipedia.org/wiki/Python_(argipena)\n",
      "Found the URL: https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86\n",
      "Found the URL: https://fr.wikipedia.org/wiki/Python\n",
      "Found the URL: https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0\n",
      "Found the URL: https://hr.wikipedia.org/wiki/Python_(razdvojba)\n",
      "Found the URL: https://io.wikipedia.org/wiki/Pitono\n",
      "Found the URL: https://id.wikipedia.org/wiki/Python\n",
      "Found the URL: https://ia.wikipedia.org/wiki/Python_(disambiguation)\n",
      "Found the URL: https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)\n",
      "Found the URL: https://it.wikipedia.org/wiki/Python_(disambigua)\n",
      "Found the URL: https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F\n",
      "Found the URL: https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)\n",
      "Found the URL: https://kg.wikipedia.org/wiki/Mboma_(nyoka)\n",
      "Found the URL: https://la.wikipedia.org/wiki/Python_(discretiva)\n",
      "Found the URL: https://lb.wikipedia.org/wiki/Python\n",
      "Found the URL: https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)\n",
      "Found the URL: https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)\n",
      "Found the URL: https://nl.wikipedia.org/wiki/Python\n",
      "Found the URL: https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3\n",
      "Found the URL: https://no.wikipedia.org/wiki/Pyton\n",
      "Found the URL: https://pl.wikipedia.org/wiki/Pyton\n",
      "Found the URL: https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)\n",
      "Found the URL: https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)\n",
      "Found the URL: https://sk.wikipedia.org/wiki/Python\n",
      "Found the URL: https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)\n",
      "Found the URL: https://sh.wikipedia.org/wiki/Python\n",
      "Found the URL: https://fi.wikipedia.org/wiki/Python\n",
      "Found the URL: https://sv.wikipedia.org/wiki/Pyton\n",
      "Found the URL: https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99\n",
      "Found the URL: https://tr.wikipedia.org/wiki/Python\n",
      "Found the URL: https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD\n",
      "Found the URL: https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86\n",
      "Found the URL: https://vi.wikipedia.org/wiki/Python\n",
      "Found the URL: https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)\n",
      "Found the URL: https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia\n",
      "Found the URL: //en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\n",
      "Found the URL: //creativecommons.org/licenses/by-sa/3.0/\n",
      "Found the URL: //foundation.wikimedia.org/wiki/Terms_of_Use\n",
      "Found the URL: //foundation.wikimedia.org/wiki/Privacy_policy\n",
      "Found the URL: //www.wikimediafoundation.org/\n",
      "Found the URL: https://foundation.wikimedia.org/wiki/Privacy_policy\n",
      "Found the URL: /wiki/Wikipedia:About\n",
      "Found the URL: /wiki/Wikipedia:General_disclaimer\n",
      "Found the URL: //en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "Found the URL: https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\n",
      "Found the URL: https://stats.wikimedia.org/#/en.wikipedia.org\n",
      "Found the URL: https://foundation.wikimedia.org/wiki/Cookie_statement\n",
      "Found the URL: //en.m.wikipedia.org/w/index.php?title=Python&mobileaction=toggle_view_mobile\n",
      "Found the URL: https://wikimediafoundation.org/\n",
      "Found the URL: https://www.mediawiki.org/\n",
      "['#mw-head', '#p-search', 'https://en.wiktionary.org/wiki/Python', 'https://en.wiktionary.org/wiki/python', '#Snakes', '#Ancient_Greece', '#Media_and_entertainment', '#Computing', '#Engineering', '#Roller_coasters', '#Vehicles', '#Weaponry', '#People', '#Other_uses', '#See_also', '/w/index.php?title=Python&action=edit&section=1', '/wiki/Pythonidae', '/wiki/Python_(genus)', '/w/index.php?title=Python&action=edit&section=2', '/wiki/Python_(mythology)', '/wiki/Python_of_Aenus', '/wiki/Python_(painter)', '/wiki/Python_of_Byzantium', '/wiki/Python_of_Catana', '/w/index.php?title=Python&action=edit&section=3', '/wiki/Python_(film)', '/wiki/Pythons_2', '/wiki/Monty_Python', '/wiki/Python_(Monty)_Pictures', '/w/index.php?title=Python&action=edit&section=4', '/wiki/Python_(programming_language)', '/wiki/CPython', '/wiki/CMU_Common_Lisp', '/wiki/PERQ#PERQ_3', '/w/index.php?title=Python&action=edit&section=5', '/w/index.php?title=Python&action=edit&section=6', '/wiki/Python_(Busch_Gardens_Tampa_Bay)', '/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)', '/wiki/Python_(Efteling)', '/w/index.php?title=Python&action=edit&section=7', '/wiki/Python_(automobile_maker)', '/wiki/Python_(Ford_prototype)', '/w/index.php?title=Python&action=edit&section=8', '/wiki/Colt_Python', '/wiki/Python_(missile)', '/wiki/Python_(nuclear_primary)', '/w/index.php?title=Python&action=edit&section=9', '/wiki/Python_Anghelo', '/w/index.php?title=Python&action=edit&section=10', '/wiki/PYTHON', '/w/index.php?title=Python&action=edit&section=11', '/wiki/Cython', '/wiki/Pyton', '/wiki/File:Disambig_gray.svg', '/wiki/Help:Disambiguation', 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0', 'https://en.wikipedia.org/w/index.php?title=Python&oldid=943216744', '/wiki/Help:Category', '/wiki/Category:Disambiguation_pages', '/wiki/Category:Disambiguation_pages_with_short_description', '/wiki/Category:All_article_disambiguation_pages', '/wiki/Category:All_disambiguation_pages', '/wiki/Category:Animal_common_name_disambiguation_pages', '/wiki/Special:MyTalk', '/wiki/Special:MyContributions', '/w/index.php?title=Special:CreateAccount&returnto=Python', '/w/index.php?title=Special:UserLogin&returnto=Python', '/wiki/Python', '/wiki/Talk:Python', '/wiki/Python', '/w/index.php?title=Python&action=edit', '/w/index.php?title=Python&action=history', '/wiki/Main_Page', '/wiki/Main_Page', '/wiki/Wikipedia:Contents', '/wiki/Wikipedia:Featured_content', '/wiki/Portal:Current_events', '/wiki/Special:Random', 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en', '//shop.wikimedia.org', '/wiki/Help:Contents', '/wiki/Wikipedia:About', '/wiki/Wikipedia:Community_portal', '/wiki/Special:RecentChanges', '//en.wikipedia.org/wiki/Wikipedia:Contact_us', '/wiki/Special:WhatLinksHere/Python', '/wiki/Special:RecentChangesLinked/Python', '/wiki/Wikipedia:File_Upload_Wizard', '/wiki/Special:SpecialPages', '/w/index.php?title=Python&oldid=943216744', '/w/index.php?title=Python&action=info', 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452', '/w/index.php?title=Special:CiteThisPage&page=Python&id=943216744&wpFormIdentifier=titleform', 'https://commons.wikimedia.org/wiki/Category:Python', '/w/index.php?title=Special:Book&bookcmd=book_creator&referer=Python', '/w/index.php?title=Special:ElectronPdf&page=Python&action=show-download-screen', '/w/index.php?title=Python&printable=yes', 'https://af.wikipedia.org/wiki/Python', 'https://als.wikipedia.org/wiki/Python', 'https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86', 'https://az.wikipedia.org/wiki/Python', 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)', 'https://be.wikipedia.org/wiki/Python', 'https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)', 'https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)', 'https://da.wikipedia.org/wiki/Python', 'https://de.wikipedia.org/wiki/Python', 'https://eo.wikipedia.org/wiki/Pitono_(apartigilo)', 'https://eu.wikipedia.org/wiki/Python_(argipena)', 'https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86', 'https://fr.wikipedia.org/wiki/Python', 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0', 'https://hr.wikipedia.org/wiki/Python_(razdvojba)', 'https://io.wikipedia.org/wiki/Pitono', 'https://id.wikipedia.org/wiki/Python', 'https://ia.wikipedia.org/wiki/Python_(disambiguation)', 'https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)', 'https://it.wikipedia.org/wiki/Python_(disambigua)', 'https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F', 'https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)', 'https://kg.wikipedia.org/wiki/Mboma_(nyoka)', 'https://la.wikipedia.org/wiki/Python_(discretiva)', 'https://lb.wikipedia.org/wiki/Python', 'https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)', 'https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)', 'https://nl.wikipedia.org/wiki/Python', 'https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3', 'https://no.wikipedia.org/wiki/Pyton', 'https://pl.wikipedia.org/wiki/Pyton', 'https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)', 'https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)', 'https://sk.wikipedia.org/wiki/Python', 'https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)', 'https://sh.wikipedia.org/wiki/Python', 'https://fi.wikipedia.org/wiki/Python', 'https://sv.wikipedia.org/wiki/Pyton', 'https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99', 'https://tr.wikipedia.org/wiki/Python', 'https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD', 'https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86', 'https://vi.wikipedia.org/wiki/Python', 'https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)', 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia', '//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License', '//creativecommons.org/licenses/by-sa/3.0/', '//foundation.wikimedia.org/wiki/Terms_of_Use', '//foundation.wikimedia.org/wiki/Privacy_policy', '//www.wikimediafoundation.org/', 'https://foundation.wikimedia.org/wiki/Privacy_policy', '/wiki/Wikipedia:About', '/wiki/Wikipedia:General_disclaimer', '//en.wikipedia.org/wiki/Wikipedia:Contact_us', 'https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute', 'https://stats.wikimedia.org/#/en.wikipedia.org', 'https://foundation.wikimedia.org/wiki/Cookie_statement', '//en.m.wikipedia.org/w/index.php?title=Python&mobileaction=toggle_view_mobile', 'https://wikimediafoundation.org/', 'https://www.mediawiki.org/']\n"
     ]
    }
   ],
   "source": [
    "links=[]\n",
    "for a in soup.find_all('a', href=True):\n",
    "    print (\"Found the URL:\", a['href'])\n",
    "    links.append(a['href'])\n",
    "    \n",
    "print (links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>DOWNLOAD THE UNITED STATES CODE</title>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All titles in the format selected compressed into a zip archive.']\n",
      "['Title 1 - General Provisions ٭']\n",
      "['Title 2 - The Congress']\n",
      "['Title 3 - The President ٭']\n",
      "['Title 4 - Flag and Seal, Seat of Government, and the States ٭']\n",
      "['Title 5 - Government Organization and Employees ٭']\n",
      "['Title 6 - Domestic Security']\n",
      "['Title 7 - Agriculture']\n",
      "['Title 8 - Aliens and Nationality']\n",
      "['Title 9 - Arbitration ٭']\n",
      "['Title 11 - Bankruptcy ٭']\n",
      "['Title 12 - Banks and Banking']\n",
      "['Title 13 - Census ٭']\n",
      "['Title 14 - Coast Guard ٭']\n",
      "['Title 15 - Commerce and Trade']\n",
      "['Title 16 - Conservation']\n",
      "['Title 17 - Copyrights ٭']\n",
      "['Title 18 - Crimes and Criminal Procedure ٭']\n",
      "['Title 19 - Customs Duties']\n",
      "['Title 20 - Education']\n",
      "['Title 21 - Food and Drugs']\n",
      "['Title 22 - Foreign Relations and Intercourse']\n",
      "['Title 23 - Highways ٭']\n",
      "['Title 24 - Hospitals and Asylums']\n",
      "['Title 25 - Indians']\n",
      "['Title 26 - Internal Revenue Code']\n",
      "['Title 27 - Intoxicating Liquors']\n",
      "['Title 28 - Judiciary and Judicial Procedure ٭']\n",
      "['Title 29 - Labor']\n",
      "['Title 30 - Mineral Lands and Mining']\n",
      "['Title 31 - Money and Finance ٭']\n",
      "['Title 32 - National Guard ٭']\n",
      "['Title 33 - Navigation and Navigable Waters']\n",
      "['Title 34 - Crime Control and Law Enforcement']\n",
      "['Title 35 - Patents ٭']\n",
      "['Title 36 - Patriotic and National Observances, Ceremonies, and Organizations ٭']\n",
      "['Title 37 - Pay and Allowances of the Uniformed Services ٭']\n",
      "['Title 39 - Postal Service ٭']\n",
      "['Title 40 - Public Buildings, Property, and Works ٭']\n",
      "['Title 41 - Public Contracts ٭']\n",
      "['Title 42 - The Public Health and Welfare']\n",
      "['Title 43 - Public Lands']\n",
      "['Title 44 - Public Printing and Documents ٭']\n",
      "['Title 45 - Railroads']\n",
      "['Title 46 - Shipping ٭']\n",
      "['Title 47 - Telecommunications']\n",
      "['Title 48 - Territories and Insular Possessions']\n",
      "['Title 49 - Transportation ٭']\n",
      "['Title 50 - War and National Defense']\n",
      "['Title 51 - National and Commercial Space Programs ٭']\n",
      "['Title 52 - Voting and Elections']\n",
      "['Title 53 [Reserved]']\n",
      "['Title 54 - National Park Service and Related Programs ٭']\n"
     ]
    }
   ],
   "source": [
    "nombres=[]\n",
    "table = soup.find_all('div',{'class':'uscitem'})\n",
    "for t in table:\n",
    "    uno = t.find_all('div',{'class':'usctitle'})\n",
    "    #print (uno)\n",
    "    for a in uno:\n",
    "        nombres.append(a.text.replace('\\n\\n','\\n').strip().split(\"\\n\"))\n",
    "for a in nombres:\n",
    "    print (a)\n",
    "        \n",
    "#each = table.find_all('div',{'class':'uscitem'})\n",
    "#article = table.find_all('article',{'class':'Box-row d-flex'})\n",
    "#h1=  table.find_all('h1',{'class':'h3 lh-condensed'})\n",
    "#for a in h1:\n",
    "#    print (a.text.replace('\\n\\n','\\n').strip().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Ten Most Wanted Fugitives — FBI</title>"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALEJANDRO ROSALES CASTILLO']\n",
      "['ARNOLDO JIMENEZ']\n",
      "['JASON DEREK BROWN']\n",
      "['YASER ABDEL SAID']\n",
      "['ALEXIS FLORES']\n",
      "['EUGENE PALMER']\n",
      "['SANTIAGO VILLALBA MEDEROS']\n",
      "['RAFAEL CARO-QUINTERO']\n",
      "['ROBERT WILLIAM FISHER']\n",
      "['BHADRESHKUMAR CHETANBHAI PATEL']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid= soup.find_all('div',{'class':'query-results pat-pager'})[0]\n",
    "el = grid.find_all('h3',{'class':'title'})\n",
    "for him in el:\n",
    "    print (him.text.replace('\\n\\n','\\n').strip().split(\"\\n\"))\n",
    "#h1=  table.find_all('h1',{'class':'h3 lh-condensed'})\n",
    "#for a in h1:\n",
    "#    print (a.text.replace('\\n\\n','\\n').strip().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Earthquakes today | Earthquake today | earthquake | earthquakes</title>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>earthquake2020-05-03   23:51:06.218min ago37.82 N  23.18 E  2ML2.9 SOUTHERN GREECE2020-05-03 23:57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earthquake2020-05-03   23:39:21.830min ago27.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>earthquake2020-05-03   23:31:20.138min ago38.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earthquake2020-05-03   23:23:57.046min ago19.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earthquake2020-05-03   23:00:26.01hr 09min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earthquake2020-05-03   22:53:44.01hr 16min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>earthquake2020-05-03   22:48:46.61hr 21min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1IIearthquake2020-05-03   22:22:38.91hr 47min ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>earthquake2020-05-03   22:05:22.62hr 04min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>earthquake2020-05-03   22:00:45.92hr 09min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fearthquake2020-05-03   22:00:38.22hr 09min ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43IVearthquake2020-05-03   21:55:53.02hr 14min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>earthquake2020-05-03   21:47:49.02hr 22min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30IVearthquake2020-05-03   21:45:39.82hr 24min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>earthquake2020-05-03   21:41:44.52hr 28min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>earthquake2020-05-03   21:20:05.82hr 49min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>earthquake2020-05-03   21:18:56.02hr 51min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>earthquake2020-05-03   21:17:55.02hr 52min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>earthquake2020-05-03   20:36:12.93hr 33min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>earthquake2020-05-03   20:26:19.03hr 43min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>earthquake2020-05-03   20:14:18.73hr 55min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1IVearthquake2020-05-03   20:04:01.14hr 05min ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>earthquake2020-05-03   20:03:33.84hr 06min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17IVearthquake2020-05-03   20:00:18.34hr 09min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>earthquake2020-05-03   19:56:47.94hr 13min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Fearthquake2020-05-03   19:36:55.54hr 33min ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>earthquake2020-05-03   19:20:32.34hr 49min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1Fearthquake2020-05-03   19:17:33.34hr 52min a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>earthquake2020-05-03   19:04:16.95hr 05min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>earthquake2020-05-03   18:41:50.85hr 28min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>earthquake2020-05-03   18:38:31.65hr 31min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16IIIearthquake2020-05-03   18:07:17.06hr 02mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>earthquake2020-05-03   18:00:57.76hr 09min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>earthquake2020-05-03   17:56:51.76hr 13min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>earthquake2020-05-03   17:46:00.36hr 24min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>earthquake2020-05-03   17:32:57.46hr 37min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Fearthquake2020-05-03   17:31:28.26hr 38min ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>earthquake2020-05-03   16:58:35.07hr 11min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>earthquake2020-05-03   16:39:13.77hr 30min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>earthquake2020-05-03   16:05:54.08hr 04min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>earthquake2020-05-03   15:56:33.18hr 13min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>earthquake2020-05-03   15:55:18.88hr 14min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>earthquake2020-05-03   15:36:06.88hr 33min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>earthquake2020-05-03   15:25:13.78hr 44min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>earthquake2020-05-03   15:24:53.08hr 45min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>earthquake2020-05-03   15:23:31.58hr 46min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>earthquake2020-05-03   15:16:03.28hr 53min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>earthquake2020-05-03   15:02:28.29hr 07min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>earthquake2020-05-03   14:59:06.09hr 10min ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>earthquake2020-05-03   14:55:49.79hr 14min ago...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   earthquake2020-05-03   23:51:06.218min ago37.82 N  23.18 E  2ML2.9 SOUTHERN GREECE2020-05-03 23:57\n",
       "0   earthquake2020-05-03   23:39:21.830min ago27.7...                                                \n",
       "1   earthquake2020-05-03   23:31:20.138min ago38.5...                                                \n",
       "2   earthquake2020-05-03   23:23:57.046min ago19.2...                                                \n",
       "3   earthquake2020-05-03   23:00:26.01hr 09min ago...                                                \n",
       "4   earthquake2020-05-03   22:53:44.01hr 16min ago...                                                \n",
       "5   earthquake2020-05-03   22:48:46.61hr 21min ago...                                                \n",
       "6   1IIearthquake2020-05-03   22:22:38.91hr 47min ...                                                \n",
       "7   earthquake2020-05-03   22:05:22.62hr 04min ago...                                                \n",
       "8   earthquake2020-05-03   22:00:45.92hr 09min ago...                                                \n",
       "9   Fearthquake2020-05-03   22:00:38.22hr 09min ag...                                                \n",
       "10  43IVearthquake2020-05-03   21:55:53.02hr 14min...                                                \n",
       "11  earthquake2020-05-03   21:47:49.02hr 22min ago...                                                \n",
       "12  30IVearthquake2020-05-03   21:45:39.82hr 24min...                                                \n",
       "13  earthquake2020-05-03   21:41:44.52hr 28min ago...                                                \n",
       "14  earthquake2020-05-03   21:20:05.82hr 49min ago...                                                \n",
       "15  earthquake2020-05-03   21:18:56.02hr 51min ago...                                                \n",
       "16  earthquake2020-05-03   21:17:55.02hr 52min ago...                                                \n",
       "17  earthquake2020-05-03   20:36:12.93hr 33min ago...                                                \n",
       "18  earthquake2020-05-03   20:26:19.03hr 43min ago...                                                \n",
       "19  earthquake2020-05-03   20:14:18.73hr 55min ago...                                                \n",
       "20  1IVearthquake2020-05-03   20:04:01.14hr 05min ...                                                \n",
       "21  earthquake2020-05-03   20:03:33.84hr 06min ago...                                                \n",
       "22  17IVearthquake2020-05-03   20:00:18.34hr 09min...                                                \n",
       "23  earthquake2020-05-03   19:56:47.94hr 13min ago...                                                \n",
       "24  Fearthquake2020-05-03   19:36:55.54hr 33min ag...                                                \n",
       "25  earthquake2020-05-03   19:20:32.34hr 49min ago...                                                \n",
       "26  1Fearthquake2020-05-03   19:17:33.34hr 52min a...                                                \n",
       "27  earthquake2020-05-03   19:04:16.95hr 05min ago...                                                \n",
       "28  earthquake2020-05-03   18:41:50.85hr 28min ago...                                                \n",
       "29  earthquake2020-05-03   18:38:31.65hr 31min ago...                                                \n",
       "30  16IIIearthquake2020-05-03   18:07:17.06hr 02mi...                                                \n",
       "31  earthquake2020-05-03   18:00:57.76hr 09min ago...                                                \n",
       "32  earthquake2020-05-03   17:56:51.76hr 13min ago...                                                \n",
       "33  earthquake2020-05-03   17:46:00.36hr 24min ago...                                                \n",
       "34  earthquake2020-05-03   17:32:57.46hr 37min ago...                                                \n",
       "35  Fearthquake2020-05-03   17:31:28.26hr 38min ag...                                                \n",
       "36  earthquake2020-05-03   16:58:35.07hr 11min ago...                                                \n",
       "37  earthquake2020-05-03   16:39:13.77hr 30min ago...                                                \n",
       "38  earthquake2020-05-03   16:05:54.08hr 04min ago...                                                \n",
       "39  earthquake2020-05-03   15:56:33.18hr 13min ago...                                                \n",
       "40  earthquake2020-05-03   15:55:18.88hr 14min ago...                                                \n",
       "41  earthquake2020-05-03   15:36:06.88hr 33min ago...                                                \n",
       "42  earthquake2020-05-03   15:25:13.78hr 44min ago...                                                \n",
       "43  earthquake2020-05-03   15:24:53.08hr 45min ago...                                                \n",
       "44  earthquake2020-05-03   15:23:31.58hr 46min ago...                                                \n",
       "45  earthquake2020-05-03   15:16:03.28hr 53min ago...                                                \n",
       "46  earthquake2020-05-03   15:02:28.29hr 07min ago...                                                \n",
       "47  earthquake2020-05-03   14:59:06.09hr 10min ago...                                                \n",
       "48  earthquake2020-05-03   14:55:49.79hr 14min ago...                                                "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "table = soup.find_all('tbody',{'id':'tbody'})[0]\n",
    "rows = table.find_all('tr')\n",
    "rows = [row.text.replace('\\n\\n\\n','\\n\\n').strip().split(\"\\n\\n\") for row in rows]\n",
    "rows\n",
    "\n",
    "colnames = rows[0]\n",
    "data = rows[1:]\n",
    "\n",
    "df = pd.DataFrame(data,columns = colnames)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://hackevents.co/hackathons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '<Response [200]>': No schema supplied. Perhaps you meant http://<Response [200]>?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-8d8a9ff6b333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://twitter.com/Mauricio_PeGo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda2/envs/python3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda2/envs/python3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda2/envs/python3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         )\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda2/envs/python3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         )\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda2/envs/python3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda2/envs/python3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '<Response [200]>': No schema supplied. Perhaps you meant http://<Response [200]>?"
     ]
    }
   ],
   "source": [
    "url = requests.get('https://twitter.com/Mauricio_PeGo')\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Wikipedia</title>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "English\n",
      "6 066 000+ articles\n",
      "\n",
      "['English', '6\\xa0066\\xa0000+ articles']\n",
      "\n",
      "Español\n",
      "1 594 000+ artículos\n",
      "\n",
      "['Español', '1\\xa0594\\xa0000+ artículos']\n",
      "\n",
      "日本語\n",
      "1 202 000+ 記事\n",
      "\n",
      "['日本語', '1\\xa0202\\xa0000+ 記事']\n",
      "\n",
      "Deutsch\n",
      "2 426 000+ Artikel\n",
      "\n",
      "['Deutsch', '2\\xa0426\\xa0000+ Artikel']\n",
      "\n",
      "Русский\n",
      "1 618 000+ статей\n",
      "\n",
      "['Русский', '1\\xa0618\\xa0000+ статей']\n",
      "\n",
      "Français\n",
      "2 207 000+ articles\n",
      "\n",
      "['Français', '2\\xa0207\\xa0000+ articles']\n",
      "\n",
      "Italiano\n",
      "1 602 000+ voci\n",
      "\n",
      "['Italiano', '1\\xa0602\\xa0000+ voci']\n",
      "\n",
      "中文\n",
      "1 114 000+ 條目\n",
      "\n",
      "['中文', '1\\xa0114\\xa0000+ 條目']\n",
      "\n",
      "Português\n",
      "1 029 000+ artigos\n",
      "\n",
      "['Português', '1\\xa0029\\xa0000+ artigos']\n",
      "\n",
      "Polski\n",
      "1 407 000+ haseł\n",
      "\n",
      "['Polski', '1\\xa0407\\xa0000+ haseł']\n"
     ]
    }
   ],
   "source": [
    "table = soup.find_all('div',{'class':'central-featured'})[0]\n",
    "each = table.find_all('a',{'class':'link-box'})\n",
    "for e in each:\n",
    "    print (e.text)\n",
    "    print (e.text.replace('\\n\\n','\\n').strip().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Find open data - data.gov.uk</title>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business and economy\n",
      "Crime and justice\n",
      "Defence\n",
      "Education\n",
      "Environment\n",
      "Government\n",
      "Government spending\n",
      "Health\n",
      "Mapping\n",
      "Society\n",
      "Towns and cities\n",
      "Transport\n"
     ]
    }
   ],
   "source": [
    "table = soup.find_all('main',{'role':'main'})[0]\n",
    "each = table.find_all('a')\n",
    "for i in each:\n",
    "    print (i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>List of languages by number of native speakers - Wikipedia</title>"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html)\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = soup.find_all('table',{'class':'wikitable sortable jquery-tablesorter'})\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
